{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c05197cf",
   "metadata": {},
   "source": [
    "# Data Pipelines & PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755b0712",
   "metadata": {},
   "source": [
    "## Connect, Load, Execute, Commit on PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba56c55b",
   "metadata": {},
   "source": [
    "- Import the psycopg2 library.\n",
    "- Connect to database.\n",
    "- Use the print function to display the Connection object.\n",
    "- Close the Connection using the close method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ff4bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "conn = psycopg2.connect('dbname=test_db user=xtang password=xtang')\n",
    "print(conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b13cdf",
   "metadata": {},
   "source": [
    "- Connect to database\n",
    "- Using the Cursor object, create a string query that selects all from the test_db table.\n",
    "- Execute the query using the execute method.\n",
    "- Fetch all the results from the table and assign it to the variable notes.\n",
    "- Close the Connection using the close method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc21a975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "conn = psycopg2.connect('dbname=test_db user=xtang password=xtang')\n",
    "cur = conn.cursor()\n",
    "cur.execute('SELECT * FROM test_db')\n",
    "one = cur.fetchone()\n",
    "total = cur.fetchall()\n",
    "notes = total\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4cbc54",
   "metadata": {},
   "source": [
    "- Connect to database\n",
    "- Write a SQL query that creates a table called users in the database, with the following columns and data types:\n",
    "    - id -- integer data type, and is a primary key.\n",
    "    - email -- text data type.\n",
    "    - name -- text data type.\n",
    "    - address -- text data type.\n",
    "- Execute the query using the execute method.\n",
    "- Don't close the connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a3d6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect('dbname=test_db user=xtang password=xtang')\n",
    "cur = conn.cursor()\n",
    "cur.execute('''CREATE TABLE users (id BIGSERIAL PRIMARY KEY, update VARCHAR(255), available INT, free INT, \n",
    "            name VARCHAR(255), long NUMERIC, lat NUMERIC, total INT)''');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21100484",
   "metadata": {},
   "source": [
    "- Connect to the database.\n",
    "- Write a SQL query that creates a table called users in the database, with the following columns and data types:\n",
    "    - id -- integer data type, and is a primary key.\n",
    "    - email -- text data type.\n",
    "    - name -- text data type.\n",
    "    - address -- text data type.\n",
    "- Execute the query using the execute method.\n",
    "- Use the commit method on the Connection object to apply the changes in the transaction to the database.\n",
    "- Close the Connection.\n",
    "\n",
    "Whenever we open a Connection in psycopg2, a new transaction will automatically be created. \n",
    "All queries run up until the <a href = \"http://initd.org/psycopg/docs/connection.html#connection.commit\"><b>commit()</b></a> method is called. When a commit is called, the PostgreSQL \n",
    "engine will run all the queries at once.\n",
    "\n",
    "If we don't want to apply the changes in the transaction block, we can call the <b>rollback()</b> \n",
    "method to remove the transaction. Not calling either commit or rollback will cause the \n",
    "transaction to stay in a pending state, and will result in the changes not being applied to \n",
    "the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08435b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect('dbname=test_db user=xtang password=xtang')\n",
    "cur = conn.cursor()\n",
    "cur.execute('CREATE TABLE users (id BIGSERIAL PRIMARY KEY, \\\n",
    "            update VARCHAR(255), \\\n",
    "            available INT, \\\n",
    "            free INT, name VARCHAR(255), \\\n",
    "            long NUMERIC, \\\n",
    "            lat NUMERIC, \\\n",
    "            total INT)');\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5109b6a",
   "metadata": {},
   "source": [
    "- Import the csv module.\n",
    "- Load the user_accounts.csv using the csv module\n",
    "- Connect to the database\n",
    "- Execute the insert query on the users table using the execute method.\n",
    "- Insert every row from the user_accounts.csv file and skip the header row.\n",
    "- Fetch all the results from the users table and assign it to the variable users.\n",
    "- Close the Connection using the close method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76ce7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('user_accounts.csv') as f:\n",
    "    reader = csv.reader(f, delimiter=\",\")\n",
    "    next(reader)\n",
    "    rows = [row for row in reader]\n",
    "\n",
    "conn = psycopg2.connect('dbname=test_db user=xtang password=xtang')\n",
    "cur = conn.cursor()\n",
    "\n",
    "for row in rows:\n",
    "    cur.execute(\"INSERT INTO test_db VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\", row)\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "cur.execute('SELECT * FROM test_db')\n",
    "users = cur.fetchall()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4da639a",
   "metadata": {},
   "source": [
    "- Connect to database\n",
    "- Load the user_accounts.csv using with open(...) as f.\n",
    "- Skip the header row.\n",
    "- Using the copy_from method, copy the file into the database.\n",
    "- Fetch all the results from the users table and assign it to the variable users.\n",
    "- Close the Connection using the close method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7ae61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect('dbname=test_db user=xtang password=xtang')\n",
    "cur = conn.cursor()\n",
    "\n",
    "with open('user_accounts.csv') as f:\n",
    "    next(f)\n",
    "    cur.copy_from(f, 'test_db', sep=',')\n",
    "\n",
    "conn.commit()\n",
    "    \n",
    "cur.execute('SELECT * FROM vbstatic2')\n",
    "data = cur.fetchall()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7614af9",
   "metadata": {},
   "source": [
    "## Creating Tables on PostgreSQL & Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785db77e",
   "metadata": {},
   "source": [
    "- Using the provided `cur` object, execute the `SELECT` query from the table.\n",
    "- Call `print()` on the description property of `cur`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e911a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "conn = psycopg2.connect('dbname=test_db user=xtang password=xtang')\n",
    "cur = conn.cursor()\n",
    "cur.execute('SELECT * FROM test_db LIMIT 0')\n",
    "print(cur.description)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429dc66e",
   "metadata": {},
   "source": [
    "- Use the provided `cur` object.\n",
    "- Create a table `ign_reviews` that contains a single field using the correct type for this data.\n",
    "- Set the `id` column as the `PRIMARY KEY`.\n",
    "- Commit your changes using the `conn` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ca4f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect('dbname=test_db user=xtang password=xtang')\n",
    "cur = conn.cursor()\n",
    "cur.execute('CREATE TABLE test_db (id BIGSERIAL PRIMARY KEY, \\\n",
    "            update VARCHAR(255), \\\n",
    "            available INT, \\\n",
    "            free INT, \\\n",
    "            name VARCHAR(255), \\\n",
    "            long NUMERIC, \\\n",
    "            lat NUMERIC, \\\n",
    "            total INT)');\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807be186",
   "metadata": {},
   "source": [
    "- Import the `csv` module.\n",
    "- Find the maximum character size of the `name` field using the `csv.reader` object.\n",
    "- Assign the size to the variable `max_name_len`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39af7e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('vb_table.csv') as f:\n",
    "    next(f)\n",
    "    reader = csv.reader(f)\n",
    "    unique_name_lens = [len(row[4]) for row in reader] #name column is row[4]\n",
    "\n",
    "max_len = max(unique_name_lens)\n",
    "#with max len 50, we can cut down VARCHAR(255) to VARCHAR(55);\n",
    "#technically adding a little bit extra, just in case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd454dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('vb_table.csv') as f:\n",
    "    next(f)\n",
    "    reader = csv.reader(f)\n",
    "    unique_name_lens = [len(row[5]) for row in reader] #long column is row[5]\n",
    "\n",
    "max_len = max(unique_name_lens)\n",
    "#longitude and latitude can be limited to just 15 decimal digits of precision; datatype double precision "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8356e436",
   "metadata": {},
   "source": [
    "`CHAR(N)` pads any empty space of a character with whitespace \" \" characters while `VARCHAR(N)` does not.\n",
    "\n",
    "The only reason the `CHAR` datatype is implemented is to keep Postgres consistent with the SQL specification.\n",
    "\n",
    "In conclusion, when using Postgres, it's better to use the `TEXT` field for uncertain sizes and `VARCHAR(N)` for ones you know the maximum length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b611aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('vb_table.csv') as f:\n",
    "    next(f)\n",
    "    reader = csv.reader(f)\n",
    "    unique_name_lens = [len(row[1]) for row in reader] #update column is row[1]\n",
    "\n",
    "max_len = max(unique_name_lens)\n",
    "#update can be limited to len 24."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ec1401",
   "metadata": {},
   "source": [
    "- Use the provided `cur` object.\n",
    "- Add columns with the proper datatype and length.\n",
    "- Commit your changes using the `conn` object.\n",
    "- Note: If you're having trouble running the `CREATE TABLE` command, you can drop the table with `DROP TABLE` before creating it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b172256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect('dbname=test_db user=xtang password=xtang')\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"DROP TABLE test_db\");\n",
    "cur.execute('CREATE TABLE test_db (id BIGSERIAL PRIMARY KEY, \\\n",
    "            update VARCHAR(24), \\\n",
    "            available INT, \\\n",
    "            free INT, \\\n",
    "            name VARCHAR(55), \\\n",
    "            long DOUBLE PRECISION, \\\n",
    "            lat DOUBLE PRECISION, \\\n",
    "            total INT)');\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8180260e",
   "metadata": {},
   "source": [
    "- Use the provided `cur` object.\n",
    "- Add the title, url, and platform, genre columns with the proper datatype and/or length if required.\n",
    "- Commit your changes using the `conn` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ec59f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect('dbname=test_db user=xtang password=xtang')\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE ign_reviews (\n",
    "        id BIGINT PRIMARY KEY,\n",
    "        score_phrase VARCHAR(11),\n",
    "        title TEXT,\n",
    "        url TEXT,\n",
    "        platform VARCHAR(20),\n",
    "        genre TEXT\n",
    "    )\n",
    "\"\"\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bacb706",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect('dbname=test_db user=xtang password=xtang')\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE ign_reviews (\n",
    "        id BIGINT PRIMARY KEY,\n",
    "        score_phrase VARCHAR(11),\n",
    "        title TEXT,\n",
    "        url TEXT,\n",
    "        platform VARCHAR(20),\n",
    "        genre TEXT,\n",
    "        score DECIMAL(3, 1)\n",
    "    )\n",
    "\"\"\")\n",
    "#for datatype DECIMAL, 3 is the total number of digits in the number,\n",
    "#1 is the number of digits after the decimal\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e42ac58",
   "metadata": {},
   "source": [
    "- Use the provided `cur` object.\n",
    "- Add the the `editors_choice` column with the proper datatype.\n",
    "- Commit your changes using the `conn` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fa4fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect('dbname=test_db user=xtang password=xtang')\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE ign_reviews (\n",
    "        id BIGINT PRIMARY KEY,\n",
    "        score_phrase VARCHAR(11),\n",
    "        title TEXT,\n",
    "        url TEXT,\n",
    "        platform VARCHAR(20),\n",
    "        genre TEXT,\n",
    "        score DECIMAL(3, 1),\n",
    "        editores_choice BOOLEAN\n",
    "    )\n",
    "\"\"\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca28889c",
   "metadata": {},
   "source": [
    "- Use the provided `cur` object.\n",
    "- Create the last column, `release_date`, with the proper datetime type.\n",
    "- Import the `csv` module and `date` module.\n",
    "- Using the `csv` module, transform the `year`, `month`, and `day` values into a date object for each row.\n",
    "- Insert the values into the created table using the `INSERT` statement from above.\n",
    "- Commit your changes using the `conn` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996a968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import date\n",
    "\n",
    "conn = psycopg2.connect('dbname=test_db user=xtang password=xtang')\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE ign_reviews (\n",
    "        id BIGINT PRIMARY KEY,\n",
    "        score_phrase VARCHAR(11),\n",
    "        title TEXT,\n",
    "        url TEXT,\n",
    "        platform VARCHAR(20),\n",
    "        score DECIMAL(3, 1),\n",
    "        genre TEXT,\n",
    "        editors_choice BOOLEAN,\n",
    "        release_date DATE\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "with open('ign.csv', 'r') as f:\n",
    "    next(f)\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        updated_row = row[:8]\n",
    "        updated_row.append(date(int(row[8]), int(row[9]), int(row[10])))\n",
    "        cur.execute(\"INSERT INTO ign_reviews VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\", updated_row)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c512d969",
   "metadata": {},
   "source": [
    "### Make SQL Database With Pandas Dataframe Using SQL Alchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da36142",
   "metadata": {},
   "source": [
    "<a href = 'http://docs.sqlalchemy.org/en/latest/core/engines.html'>SQL Alchemy Documentation: Engine Configuration</a><br>\n",
    "<a href = 'http://docs.sqlalchemy.org/en/latest/core/type_basics.html#sql-standard-and-multiple-vendor-types'>SQL Alchemy Documentation: dtypes</a>\n",
    "\n",
    "`dialect+driver://username:password@host:port/database`<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6473cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be9f25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is a pandas dataframe prepared seperately\n",
    "engine = create_engine('postgresql+psycopg2://xtang:xtang@localhost/text_db')\n",
    "data.to_sql('users', engine, dtype = {'id': sqlalchemy.types.BIGINT, \\\n",
    "                                         'update':sqlalchemy.types.TIMESTAMP(timezone=False), \\\n",
    "                                         'available': sqlalchemy.types.INT, \\\n",
    "                                         'free': sqlalchemy.types.INT, \\\n",
    "                                         'total': sqlalchemy.types.INT, \\\n",
    "                                         'name': sqlalchemy.types.CHAR(length=55), \\\n",
    "                                         'long': sqlalchemy.types.NUMERIC(precision=10, scale=8, asdecimal=True), \\\n",
    "                                         'lat': sqlalchemy.types.NUMERIC(precision=10, scale=8, asdecimal=True)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19beab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    conn.execute('ALTER TABLE users ADD PRIMARY KEY (index);')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7307b7d9",
   "metadata": {},
   "source": [
    "## Manage Tables PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2797dbd",
   "metadata": {},
   "source": [
    "- Using the provided `cur` object, execute the `ALTER TABLE` query to rename the `old_ign_reviews` table to `ign_reviews`.\n",
    "- Commit your changes.\n",
    "- Execute the `SELECT` query from the example on the table `ign_reviews`.\n",
    "- Call `print()` on the `cur.description` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4081fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect('dbname=test_db user=xtang password=xtang')\n",
    "cur = conn.cursor()\n",
    "cur.execute('ALTER TABLE users RENAME TO user')\n",
    "conn.commit()\n",
    "cur.execute('SELECT * FROM user LIMIT 0')\n",
    "print(cur.description)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874d30ec",
   "metadata": {},
   "source": [
    "- Use the provided `cur` object.\n",
    "- Drop the redundant column `full_url` from `ign_reviews`.\n",
    "- Commit your changes using the `conn` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45f7e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect('dbname=test_db user=xtang password=xtang')\n",
    "cur = conn.cursor()\n",
    "cur.execute('ALTER TABLE ign_reviews DROP COLUMN full_url')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9480e996",
   "metadata": {},
   "source": [
    "- Use the provided `cur` object.\n",
    "- Change the column type of `id` to `BIGINT` for `ign_reviews`.\n",
    "- Commit your changes using the `conn` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57a051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect('dbname=test_db user=xtang password=xtang')\n",
    "cur = conn.cursor()\n",
    "cur.execute('ALTER TABLE ign_reviews ALTER COLUMN id TYPE BIGINT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72d3660",
   "metadata": {},
   "source": [
    "- Use the provided `cur` object.\n",
    "- Change the column name of `title_of_game_review` to `title` for `ign_reviews`.\n",
    "- Commit your changes using the `conn` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7199df",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect('dbname=test_db user=xtang password=xtang')\n",
    "cur = conn.cursor()\n",
    "cur.execute('ALTER TABLE ign_reviews RENAME COLUMN title_of_game_review TO title')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9140bc4d",
   "metadata": {},
   "source": [
    "- Use the provided `cur` object.\n",
    "- Add the the `release_date` column with the proper datatype.\n",
    "- Commit your changes using the `conn` object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bf6ee1",
   "metadata": {},
   "source": [
    "-- Default each entry to Jan 1st, 1991.<Br>\n",
    "`ALTER TABLE ign_reviews ADD COLUMN release_date DATE DEFAULT 01-01-1991`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0b52a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect('dbname=test_db user=xtang password=xtang')\n",
    "cur = conn.cursor()\n",
    "cur.execute('ALTER TABLE ign_reviews ADD COLUMN release_date DATE')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c9a747",
   "metadata": {},
   "source": [
    "- Use the provided `cur` object.\n",
    "- Update the `release_date` column for `ign_reviews` using `UPDATE` and for every entry:\n",
    "- Insert the combination of the columns `release_day`, `release_month`, `release_year`.\n",
    "- Use the string merger to create the date-like string with the corresponding date format representation.\n",
    "- Use the `to_date()` function to create the date objects for the column.\n",
    "- Commit your changes using the `conn` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e55afbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect('dbname=test_db user=xtang password=xtang')\n",
    "cur = conn.cursor()\n",
    "cur.execute('''\n",
    "UPDATE ign_reviews SET release_date = to_date(\n",
    "release_day || '-' || release_month || '-' || release_year, 'DD-MM-YYYY');\n",
    ")\n",
    "'''\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8dc367",
   "metadata": {},
   "source": [
    "- Use the provided `cur` object.\n",
    "- Using `ALTER TABLE` with `DROP COLUMN` to drop the `release_day`, `release_month`, and `release_year` redundant columns.\n",
    "- Commit your changes using the `conn` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d87f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect('dbname=test_db user=xtang password=xtang')\n",
    "cur = conn.cursor()\n",
    "cur.execute('ALTER TABLE ign_reviews DROP COLUMN release_day')\n",
    "cur.execute('ALTER TABLE ign_reviews DROP COLUMN release_month')\n",
    "cur.execute('ALTER TABLE ign_reviews DROP COLUMN release_year')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971397c6",
   "metadata": {},
   "source": [
    "## Loading and Extracting Data PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987521f0",
   "metadata": {},
   "source": [
    "- Use the provided `cur` variable.\n",
    "- Load the `ign.csv` file found in terminal table using the `csv` module.\n",
    "- Run the insert query on the `ign_reviews` table using the execute method using the prepared statement.\n",
    "- Insert every row from the `ign_review.csv` file except for the header row.\n",
    "- Note that the last column is `release_date` instead of the 3 `release_day`, `release_month`, and `release_year` columns.\n",
    "- Commit your changes using the `conn` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5659b42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645944d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect('dbname=test_db user=xtang password=xtang')\n",
    "cur = conn.cursor()\n",
    "with open('ign.csv', 'r') as f:\n",
    "    next(f)\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        cur.execute(\"INSERT INTO ign_reviews VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\", row)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfde40a",
   "metadata": {},
   "source": [
    "- Use the provided `cur` variable.\n",
    "- Load the `ign.csv` file found in terminal table using the `csv` module.\n",
    "- Create a comma-seperated string of mogrified values using the `mogrify()` method.\n",
    "- Mogrify every row from the `ign_review.csv` file and skip the header row.\n",
    "- Set the comma-seperated string to the variable `mogrified_values`.\n",
    "- Execute the insert query on the `ign_reviews` table using the execute method.\n",
    "- Concat the `mogrified_values` to the `INSERT` statement.\n",
    "- Commit your changes using the `conn` object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653dde8a",
   "metadata": {},
   "source": [
    "The prepared statement safely converts the Python types to the Postgres types when executing an `INSERT` statement. The conversion takes place in a seperate step within the `psycopg2` library using a method called `mogrify()`\n",
    "\n",
    "> ` cur.mogrify(\"INSERT INTO test (num, data) VALUES (%s, %s)\", (42, 'bar'))\n",
    "\"INSERT INTO test (num, data) VALUES (42, E'bar')\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c93d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect('dbname=test_db user=xtang password=xtang')\n",
    "cur = conn.cursor()\n",
    "with open('ign.csv', 'r') as f:\n",
    "    next(f)\n",
    "    reader = csv.reader(f)\n",
    "    mogrified = [cur.mogrify(\"(%s, %s, %s, %s, %s, %s, %s, %s, %s)\", row).decode('utf-8') for row in reader]\n",
    "mogrified_values = \",\".join(mogrified)\n",
    "cur.execute(\"INSERT INTO ign_reviews VALUES \" + mogrified_values)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3ceb62",
   "metadata": {},
   "source": [
    "- Use the provided `cur` variable.\n",
    "- Load the `ign.csv` file.\n",
    "- Execute the `COPY ... FROM` method on the `ign_reviews` table using the `copy_expert` method.\n",
    "- Add the `CSV` and `HEADER` options.\n",
    "- Commit your changes using the `conn` object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5750424d",
   "metadata": {},
   "source": [
    "The `cur.copy_from()` method provides a useful API for file copying but only if the file is defined with a simple seperator (delimiter) character\n",
    "\n",
    "To use the `copy_expert()` method, you first have to declare the full `COPY` statement and then pass in the Python file descriptor. The biggest difference you may notice is that we don't copy from a file, but from the `STDIN` which in this case is the Python file object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105198b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect('dbname=test_db user=xtang password=xtang')\n",
    "cur = conn.cursor()\n",
    "with open('ign.csv',  'r') as f:\n",
    "    cur.copy_expert('COPY ign_reviews FROM STDIN WITH CSV HEADER', f)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bce46d",
   "metadata": {},
   "source": [
    "- Using the time module, play around to determine which of the last three methods we introduced is the fastest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34413fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "conn = psycopg2.connect('dbname=test_db user=xtang password=xtang')\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Multiple single insert statements.\n",
    "start = time.time()\n",
    "with open('ign.csv', 'r') as f:\n",
    "    next(f)\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        cur.execute(\n",
    "            \"INSERT INTO ign_reviews VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\",\n",
    "            row\n",
    "        )\n",
    "conn.rollback()\n",
    "print(\"Single statment insert: \", time.time() - start)\n",
    "        \n",
    "# Multiple mogrify insert.\n",
    "start = time.time()\n",
    "with open('ign.csv', 'r') as f:\n",
    "    next(f)\n",
    "    reader = csv.reader(f)\n",
    "    mogrified = [ \n",
    "        cur.mogrify(\"(%s, %s, %s, %s, %s, %s, %s, %s, %s)\", row).decode('utf-8')\n",
    "        for row in reader\n",
    "    ] \n",
    "    mogrified_values = \",\".join(mogrified) \n",
    "    cur.execute('INSERT INTO ign_reviews VALUES ' + mogrified_values)\n",
    "conn.rollback()\n",
    "print(\"Multiple mogrify insert: \", time.time() - start)\n",
    "\n",
    "# Copy expert method.\n",
    "start = time.time()\n",
    "with open('ign.csv', 'r') as f:\n",
    "    cur.copy_expert('COPY ign_reviews FROM STDIN WITH CSV HEADER', f)\n",
    "conn.rollback()\n",
    "print(\"Copy expert method: \", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02b3739",
   "metadata": {},
   "source": [
    "Single statment insert:  2.948253631591797<br>\n",
    "Multiple mogrify insert:  1.0108413696289062<br>\n",
    "Copy expert method:  0.16642284393310547<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f634f3",
   "metadata": {},
   "source": [
    "- Use the provided `cur` variable.\n",
    "- Open a `old_ign_reviews.csv` file using the statement with `open()` as `f`.\n",
    "- Execute the `COPY ... TO` method on the `old_ign_reviews` table using the `copy_expert` method.\n",
    "- Add the `CSV` and `HEADER` options.\n",
    "- Write it out to the `old_ign_reviews.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb26381",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect('dbname=test_db user=xtang password=xtang')\n",
    "cur = conn.cursor()\n",
    "\n",
    "with open('old_ign_reviews.csv', 'w') as f:\n",
    "    cur.copy_expert('COPY old_ign_reviews TO STDOUT CSV HEADER', f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8276028",
   "metadata": {},
   "source": [
    "- Use the provided `cur` variable.\n",
    "- Open a `old_ign_reviews.csv` file using the statement with `open()` as `f`.\n",
    "- Execute the `COPY ... TO` method on the `old_ign_reviews` table using the `copy_expert` method.\n",
    "- Add the `CSV` and `HEADER` options.\n",
    "- Process the data and transform it to match the `ign_reviews` table.\n",
    "- Insert the processed rows into the `ign_reviews` table using whatever `INSERT` command you want.\n",
    "- Commit your changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84db5164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import date\n",
    "\n",
    "conn = psycopg2.connect('dbname=test_db user=xtang password=xtang')\n",
    "cur = conn.cursor()\n",
    "with open('old_ign_reviews.csv', 'r+') as f:\n",
    "    cur.copy_expert('COPY old_ign_reviews TO STDOUT WITH CSV HEADER', f)\n",
    "    f.seek(0)\n",
    "    next(f) #skip header\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        updated_row = row[:8]\n",
    "        updated_row.append(date(int(row[8]), int(row[9]), int(row[10])))\n",
    "        cur.execute(\"INSERT INTO ign_reviews VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\", updated_row)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9127b23",
   "metadata": {},
   "source": [
    "This approach is great for tables that contain less than a million rows but as the size of the table increases, it becomes unlikely that this approach would work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8e0adf",
   "metadata": {},
   "source": [
    "- Use the provided `cur` variable.\n",
    "- Insert rows into the `ign_reviews` table using the `INSERT` with `SELECT` from the `old_ign_reviews` table.\n",
    "- Commit your changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8866799",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect('dbname=test_db user=xtang password=xtang')\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute('''\n",
    "INSERT INTO ign_reviews (id, score_phrase, title, url, platform, score, genre, editors_choice, release_date)\n",
    "\n",
    "SELECT id, score_phrase, title_of_game_review, url, platform, score, genre, editors_choice, \n",
    "       to_date(release_day || '-' || release_month || '-' || release_year, 'DD-MM-YYYY') as release_date \n",
    "FROM old_ign_reviews\n",
    "''')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06221071",
   "metadata": {},
   "source": [
    "## User and Database Management PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5157134",
   "metadata": {},
   "source": [
    "- Import the `psycopg2` library.\n",
    "- Use the `print` function to display the Connection object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725f50a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "conn = psycopg2.connect(dbname=\"test_db\", user=\"xtang\", password = \"xtang\")\n",
    "print(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f361ebc7",
   "metadata": {},
   "source": [
    "- Create cursor object using the `.cursor()` method.\n",
    "- Create a new user that has the following options:\n",
    "    - Has a password with the value somepassword.\n",
    "    - Not a superuser.\n",
    "- Commit the transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d0b0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname = \"test_db\", user = \"xtang\")\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"CREATE USER xtang1 WITH PASSWORD 'somepassword' NOSUPERUSER\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeedfd6",
   "metadata": {},
   "source": [
    "- Use the created Cursor object using the variable `cur`.\n",
    "- Revoke all privileges from user `xtang1` on the table `user`.\n",
    "- Commit the transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c77acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname = \"test_db\", user = \"xtang\")\n",
    "cur = conn.cursor()\n",
    "cur.execute('REVOKE ALL ON user FROM xtang1;')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab91af4",
   "metadata": {},
   "source": [
    "- Use the created Cursor object using the variable `cur`.\n",
    "- Grant the `SELECT` privilege to user `xtang1` on the table `user`.\n",
    "- Commit the transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98321412",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname=\"test_db\", user=\"xtang\")\n",
    "cur = conn.cursor()\n",
    "cur.execute('GRANT SELECT ON user TO xtang1')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fbfacd",
   "metadata": {},
   "source": [
    "- Use the created Cursor object using the variable `cur`.\n",
    "- Create a `readonly` group by doing the following:\n",
    "    - Create a `NOLOGIN` group named readonly.\n",
    "    - Revoke all privilges from the group on `user_accounts`.\n",
    "    - Grant `SELECT` to the group on `user_accounts`.\n",
    "- Assign `data_viewer` to the `readonly` group.\n",
    "- Commit the transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b55f423",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname=\"test_db\", user=\"xtang\")\n",
    "cur = conn.cursor()\n",
    "cur.execute('CREATE GROUP readonly NOLOGIN')\n",
    "cur.execute('REVOKE ALL ON user FROM readonly')\n",
    "cur.execute('GRANT SELECT ON user TO readonly')\n",
    "cur.execute('GRANT readonly TO xtang1')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe15c7a",
   "metadata": {},
   "source": [
    "- Use the created Cursor object using the variable `cur`.\n",
    "- Create a database called `accounts` where the owner is the user `data_viewer`.\n",
    "- Don't commit the transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d5b37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname=\"test_db\", user=\"xtang\")\n",
    "# Connection set to autocommit\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "cur.execute('CREATE DATABASE accounts OWNER xtang')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ee2a91",
   "metadata": {},
   "source": [
    "- Use the created Cursor object using the variable `cur`.\n",
    "- Create a database called `top_secret`.\n",
    "- Reconnect to the `top_secret` database with the `xtang` user.\n",
    "- Create a table in `top_secret` called `documents` following schema:\n",
    "    - `id` with `INT`.\n",
    "    - `info` with `TEXT`.\n",
    "- Create a group called `spies` with only the following privileges:\n",
    "    - `NOLOGIN`.\n",
    "    - Can only `INSERT`, `SELECT`, and `UPDATE` on documents.\n",
    "- Create a user named `double_o_7` with the following options:\n",
    "    - Can create a database.\n",
    "    - Password is 'shakennotstirred'.\n",
    "    - In group `spies`.\n",
    "- Commit the transaction.\n",
    "- Connect to the `top_secret` database using `psycopg2.connect()` and the user `double_o_7`.\n",
    "    - Assign the connection variable to `conn_007`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a809d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname=\"test_db\", user=\"xtang\")\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"CREATE DATABASE top_secret OWNER xtang\")\n",
    "conn = psycopg2.connect(dbname=\"top_secret\", user=\"xtang\")\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE documents(id INT, info TEXT);\n",
    "CREATE GROUP spies NOLOGIN;\n",
    "REVOKE ALL ON documents FROM spies;\n",
    "GRANT SELECT, INSERT, UPDATE ON documents TO spies;\n",
    "CREATE USER double_o_7 WITH CREATEDB PASSWORD 'shakennotstirred' IN GROUP spies;\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "conn_007 = psycopg2.connect(dbname='top_secret', user='double_o_7', password='shakennotstirred')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ae8030",
   "metadata": {},
   "source": [
    "## Postgres Internals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde85555",
   "metadata": {},
   "source": [
    "- Import the `psycopg2` library.\n",
    "- Use the `print` function to display the Connection object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10d1188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "conn = psycopg2.connect(dbname=\"test_db\", user=\"xtang1\", password=\"admin123\")\n",
    "print(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbfaa5f",
   "metadata": {},
   "source": [
    "This seems to let any user get into any db, and it allows any password to fly. Resources to fix this:\n",
    "- https://stackoverflow.com/questions/21054549/postgres-accepts-any-password\n",
    "- https://dba.stackexchange.com/questions/17790/created-user-can-access-all-databases-in-postgresql-without-any-grants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1ddc37",
   "metadata": {},
   "source": [
    "- Use the provided `cur` object.\n",
    "- Using the `SELECT` query, grab the `table_name` column from the `information_schema.tables` table with the `ORDER BY` option on the `table_name` column.\n",
    "- Fetch all the results and assign them to the variable `table_names`.\n",
    "- Loop through `table_names`:\n",
    "- Print each `table_name` from the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9737fbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname=\"test_db\", user=\"xtang\")\n",
    "cur = conn.cursor()\n",
    "cur.execute('SELECT table_name FROM information_schema.tables ORDER BY table_name')\n",
    "table_names = cur.fetchall()\n",
    "for name in table_names:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8191ca4",
   "metadata": {},
   "source": [
    "In the output, you would have noticed many tables that started with the prefix `pg_*`. Each one of these tables is part of the `pg_catalog` group of internal tables. These are the system catalog tables. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e53a5fa",
   "metadata": {},
   "source": [
    "- Use the provided `cur` object.\n",
    "- Using the `SELECT` query, grab the `table_name` column from the `information_schema.tables` table.\n",
    "    - Find user created by filtering the query on the `table_schema` column.\n",
    "    - `ORDER BY` the `table_name` again.\n",
    "- Loop through `cur.fetchall()` and print each `table_name` from the query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba21c302",
   "metadata": {},
   "source": [
    "In Postgres, schemas are used as a namespace for tables, with the distinct purpose of seperating them into isolated groups or sets within a single database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0619e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "conn = psycopg2.connect(dbname=\"test_db\", user=\"xtang\")\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT table_name FROM information_schema.tables WHERE table_schema='public' ORDER BY table_name\")\n",
    "for table_name in cur.fetchall():\n",
    "    name = table_name[0]\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fb711f",
   "metadata": {},
   "source": [
    "- Import `AsIs` from `psycopg2.extensions`.\n",
    "- Within the loop for `cur.fetchall()` for each table name:\n",
    "    - Run a `SELECT` query with the table variable using `AsIs`.\n",
    "    - Print the `cur.description` attribute.\n",
    "    - Print a black space to seperate the descriptions at the end of each loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaf9a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg2.extensions import AsIs\n",
    "\n",
    "conn = psycopg2.connect(dbname=\"test_db\", user=\"xtang\")\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT table_name FROM information_schema.tables WHERE table_schema='public'\")\n",
    "for table in cur.fetchall(): \n",
    "     table = table[0]\n",
    "     cur.execute(\"SELECT * FROM %s LIMIT 0\", [AsIs(table)])\n",
    "     print(cur.description, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eef9de1",
   "metadata": {},
   "source": [
    "- Use the provided `cur` object.\n",
    "- Using `execute()`, `SELECT` from the `pg_catalog.pg_type`, choose two columns that can map an integer type code to a human - readable string.\n",
    "- Create a dict and assign it to the variable `type_mappings`.\n",
    "- Loop through the returned `SELECT` query and map the integer type code to the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ad23f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname=\"test_db\", user=\"xtang\")\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT oid, typname FROM pg_catalog.pg_type\")\n",
    "type_mappings = {\n",
    "    int(oid): typname\n",
    "    for oid, typname in cur.fetchall()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a710093d",
   "metadata": {},
   "source": [
    ">One interesting thing to note about `pg_catalog.pg_type`is that it can be used to create your own Postgres types from scratch. Let's put all this together and create our own table descriptions. We want to rewrite the description attributes from a list of tuples towards something human readable. In the following exercise, we will assemble output from the previous exercises into a dictionary.\n",
    "\n",
    "- Use the provided `cur`, `type_mappings`, and `table_names` objects.\n",
    "- Create a dict and assign it to the variable `readable_description`.\n",
    "- Loop through the `table_names` with the table variable and do the following:\n",
    "    - Get the description attribute for the given table.\n",
    "    - Map the name of the table to a dictionary with a columns key.\n",
    "    - Recreate the columns list from the screen example by iterating through the description, and mapping the appropriate types.\n",
    "- Print the `readable_description` dictionary at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac30b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg2.extensions import AsIs\n",
    "conn = psycopg2.connect(dbname=\"test_db\", user=\"xtang\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "readable_description = {}\n",
    "#for table in table_names:\n",
    "    #cur.execute(\"SELECT * FROM %s LIMIT 0\", [AsIs(table)])\n",
    "cur.execute(\"SELECT * FROM stormdata LIMIT 0\")\n",
    "readable_description[table] = dict(\n",
    "    columns=[\n",
    "        dict(\n",
    "            name=col.name,\n",
    "            type=type_mappings[col.type_code],\n",
    "            length=col.internal_size\n",
    "        )\n",
    "        for col in cur.description\n",
    "    ]\n",
    ")\n",
    "print(readable_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc94f3fa",
   "metadata": {},
   "source": [
    "- Use the provided `cur` object and `AsIs` class.\n",
    "- Loop through the `readable_description` keys:\n",
    "    - Fetch the value of each table's row count and assign it to a `total` key for that table.\n",
    "- Print the `readable_description` dictionary at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c138ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg2.extensions import AsIs\n",
    "conn = psycopg2.connect(dbname=\"test_db\", user=\"xtang\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "#for table in readable_description.keys():\n",
    "    #cur.execute(\"SELECT COUNT(*) FROM %s\", [AsIs(table)])\n",
    "cur.execute(\"SELECT COUNT(*) FROM stormdata\")\n",
    "readable_description[table][\"total\"] = cur.fetchone()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e96c60",
   "metadata": {},
   "source": [
    "- Use the provided `cur` object and `AsIs` class.\n",
    "- Loop through the `readable_description` keys and run the following:\n",
    "    - Select the first 100 rows with `SELECT ... LIMIT` using `execute()` and `AsIs`.\n",
    "    - Fetch the all the rows and assign it to the `readable_description` dictionary for the given table using the `sample_rows` key.\n",
    "- Print the `readable_description` dictionary at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5445727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg2.extensions import AsIs\n",
    "conn = psycopg2.connect(dbname=\"test_db\", user=\"xtang\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "#for table in readable_description.keys():\n",
    "#    cur.execute(\"SELECT * FROM %s LIMIT 100\", [AsIs(table)])\n",
    "cur.execute(\"SELECT * FROM stormdata LIMIT 100\")\n",
    "readable_description[table][\"sample_rows\"] = cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3f8866",
   "metadata": {},
   "source": [
    "## Debugging PostgresSQL Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6f0292",
   "metadata": {},
   "source": [
    "- Use the provided `cur` object.\n",
    "- Run the `EXPLAIN` command for a `SELECT` all query on the `vbstatic` table.\n",
    "- Call `.fetchall()` and pretty print the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361ce08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pprint as pp\n",
    "\n",
    "conn = psycopg2.connect(dbname=\"test_db\", user=\"xtang\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"EXPLAIN SELECT * FROM user\")\n",
    "pp.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efbf8ff",
   "metadata": {},
   "source": [
    "> Let's describe the path a query takes when you call `cur.execute()`.\n",
    ">\n",
    ">Path of a query:\n",
    ">\n",
    ">1. The query is parsed for correct syntax. If there are any errors, the query does not execute and you receive an error message. If error-free, then the query is transformed into a query tree.\n",
    ">\n",
    ">2. A rewrite system takes the query tree and checks against the system catalog internal tables for any special rules. Then, if there are any rules, it rewrites them into the query tree.\n",
    ">\n",
    ">3. The rewritten query tree is then processed by the planner/optimizer which creates a query plan to send to the executor. The planner ensures that this is the fastest possible route for query execution.\n",
    ">\n",
    ">4. The executor takes in the query plan, runs each step, then returns back any rows it found.\n",
    ">\n",
    ">When we run the EXPLAIN command, we are examining the query at the third step in its path. In this step, the planner (or optimizer) is responsible for taking the written query and finding the fastest and most efficient way of returning the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7017a033",
   "metadata": {},
   "source": [
    "- Use the provided `cur` object.\n",
    "- Run the `EXPLAIN` command on a query that returns a `COUNT` of rows greater than the year 2012-01-01 for `homeless_by_coc`.\n",
    "- Call `.fetchall()` and <a href=\"https://docs.python.org/3/library/pprint.html\">pretty print</a> the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fd5550",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname=\"test_db\", user=\"xtang\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"EXPLAIN SELECT COUNT(*) from user WHERE update > '2018-02-22'\")\n",
    "pp.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379cf95e",
   "metadata": {},
   "source": [
    "> The executor will start by running a sequential scan on the table, filter by the year value, and then run the aggregator on those returned results. The plan of execution closely resembles a tree of commands  starting from the bottom and working its way up  but it is not clearly shown by this output format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79941551",
   "metadata": {},
   "source": [
    "- Use the provided `cur` object.\n",
    "- Run the `EXPLAIN` command on a query that returns a `COUNT` of rows greater than the year 2012-01-01 for `homeless_by_coc`.\n",
    "    - Format the ouptut with the `json` type.\n",
    "- Call `.fetchall()` and pretty print the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006515b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname=\"test_db\", user=\"xtang\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"EXPLAIN (format json) SELECT COUNT(*) from user WHERE update > '2018-02-22'\")\n",
    "pp.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a938113",
   "metadata": {},
   "source": [
    "The cost of the operation as estimated by the optimizer's cost-based approach. For statements that use the rule-based approach, this column is null. Cost is not determined for table access operations. The value of this column does not have any particular unit of measurement, it is merely a weighted value used to compare costs of execution plans.  \n",
    "https://docs.oracle.com/cd/A58617_01/server.804/a58246/explan.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b308b74",
   "metadata": {},
   "source": [
    "> The `Startup Cost` represents the time it takes before a rows can be returned (something like sorting, or collecting the rows and aggregating them). <br>\n",
    ">`Total Cost` includes `Startup Cost` and is the total time it takes to run the node plan until completion. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c505b31e",
   "metadata": {},
   "source": [
    "- Use the provided `cur` object.\n",
    "- Practice running different `EXPLAIN` commands on any of the tables in the database. Here is one to try:\n",
    "    - `SELECT count FROM homeless_by_coc`\n",
    "    - `SELECT postal FROM state_info WHERE state='Alabama'`\n",
    "    - `SELECT state, SUM(count) FROM homeless_by_coc GROUP BY state HAVING SUM(count) > 100000 ORDER BY state`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ce09d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname=\"test_db\", user=\"xtang\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"EXPLAIN SELECT count(*) FROM user\")\n",
    "pp.pprint(cur.fetchall())\n",
    "\n",
    "cur.execute(\"EXPLAIN SELECT available FROM user WHERE free=0\")\n",
    "pp.pprint(cur.fetchall())\n",
    "\n",
    "cur.execute(\"EXPLAIN SELECT available, SUM(free) FROM user GROUP BY available\")\n",
    "pp.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a32b894",
   "metadata": {},
   "source": [
    "> Under the hood, `EXPLAIN` runs several queries on internal tables to give us the estimated data. One of these tables is the `pg_class` table where the estimated costs and rows are stored. This table only stores estimates of rows and costs (not actual values) so `EXPLAIN` can only give us approximate values for our queries.\n",
    ">\n",
    ">If we want to see, and force, actual runtime statistics of our queries, we need to use the `ANALYZE` option of the `EXPLAIN` query. With `ANALYZE`, the `EXPLAIN` command will execute our given query, wait for the results, then return the output with the recorded values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c034473",
   "metadata": {},
   "source": [
    "- Use the provided `cur` object.\n",
    "- Run the `EXPLAIN` command on a query that returns a `COUNT` of rows greater than the year 2012-01-01 for `homeless_by_coc`.\n",
    "    - Add the `ANALYZE` option to the `EXPLAIN` command.\n",
    "    - Format the ouptut with the `json` type.\n",
    "    - Note that we are trying to add two options for `EXPLAIN`.\n",
    "- Call `.fetchall()` and pretty print the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6322de",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"EXPLAIN (ANALYZE, format json) SELECT COUNT(*) from vbstatic WHERE update > '2018-02-22'\")\n",
    "pp.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c9e05d",
   "metadata": {},
   "source": [
    ">Using the `ANALYZE` option, we have both estimates and actual times (in milliseconds) side by side. Furthermore, we are presented with the total execution time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d762c0",
   "metadata": {},
   "source": [
    "- Use the provided `cur` and conn objects.\n",
    "- Run the `EXPLAIN ANALYZE` command on a `DELETE` query that deletes all the rows in `state_household_incomes`.\n",
    "    - Format the ouptut with the `json` type.\n",
    "- Rollback the delete command.\n",
    "- Call `.fetchall()` and pretty print the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945a8758",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname=\"valenbisi2018\", user=\"nmolivo\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"EXPLAIN (ANALYZE, FORMAT json) DELETE FROM vbstatic\")\n",
    "# Rollback the change.\n",
    "conn.rollback()\n",
    "pp.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017f6eec",
   "metadata": {},
   "source": [
    "- Use the provided `cur` object.\n",
    "- Run `EXPLAIN ANALYZE` on a select from `homeless_by_coc` and `state_info`:\n",
    "    - Select columns `state`, `coc_number`, and `coc_name` from `homeless_by_coc`.\n",
    "    - Select column name from `state_info`.\n",
    "    - Join on `homless_by_coc.state` and `state_info.postal`.\n",
    "    - Format the ouptut with the `json` type.\n",
    "- Call `fetchall()` and pretty print the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62b0fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('''\n",
    "    EXPLAIN (ANALYZE, FORMAT json) SELECT hbc.state, hbc.coc_number, hbc.coc_name, \n",
    "    si.name FROM homeless_by_coc as hbc, state_info as si WHERE hbc.state = si.postal\n",
    "    '''\n",
    "           )\n",
    "pp.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efea608f",
   "metadata": {},
   "source": [
    "The output of the `EXPLAIN ANALYZE` command reveals the inefficiency of the join. In the list of plans, each node must first run a Seq Scan which is a loop through each of the tables. Before the join can occur, a loop is performed twice: once in `homeless_by_coc` and once in `state_info`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336c9c0f",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63eee372",
   "metadata": {},
   "source": [
    "> We will work through strategies to make it more efficient. To begin, we will learn about different query scans a `SELECT` performs. Next, we will introduce the concept of an index, and how indexes are used to speed up common queries. \n",
    ">\n",
    ">An index creates a b-tree structure on a column, separate from the table, which allows filtered queries to perform binary search.\n",
    ">\n",
    "> Using an index, we will show that we can speed up queries to run in $Olog(n)$ complexity from $O(n)$ We will both prove it theoretically, and then using `EXPLAIN`, show how query speeds will decrease as a result of adding the index. Finally, we will finish by demonstrating the positive effect an index can have on joins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c90b355",
   "metadata": {},
   "source": [
    "- Use the provided `cur` object.\n",
    "- Run the `EXPLAIN` command for a `SELECT` all query on the `homeless_by_coc` table filtering by `id`=10.\n",
    "- Format the `EXPLAIN` query with json output.\n",
    "- Call `.fetchall()` and pretty print the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7da866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pprint as pp\n",
    "\n",
    "conn = psycopg2.connect(dbname=\"test_db\", user=\"xtang\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"EXPLAIN (FORMAT json) SELECT * FROM user WHERE index = 5\")\n",
    "pp.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1e5648",
   "metadata": {},
   "source": [
    "Since we were searching through the primary key, (see `user_pkey` in the output), Our query knows to stop searching after finding the first record where `index = 5` since in Postgres, all primary key values are unique. Our query does a binary search.<br>\n",
    ">A binary search can help us find an item in a list efficiently if we know the list is ordered. We can check the middle element of the list, compare it to the item we're looking for, and continue narrowing our search in this manner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3c7406",
   "metadata": {},
   "source": [
    "- Use the provided `cur` object.\n",
    "- Run the `EXPLAIN` command on a select query from each table that filters on their corresponding primary keys:\n",
    "    - Format by json.\n",
    "    - `homeless_by_coc.id` equal to 5 and assign `fetchall()` to the variable `homeless_query_plan`.\n",
    "    - `state_info.name` equal to Alabama and assign `fetchall()` to the variable `state_query_plan`.\n",
    "    - `state_household_incomes.state` equal to Georgia and assign `fetchall()` to the variable `incomes_query_plan`.\n",
    "- For each `query_plan` variable (`homeless_query_plan`, `state_query_plan`, `incomes_query_plan`), pretty print the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5d03ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"EXPLAIN (format json) SELECT * FROM homeless_by_coc WHERE id=10\")\n",
    "homeless_query_plan = cur.fetchall()\n",
    "pp.pprint(homeless_query_plan)\n",
    "\n",
    "cur.execute(\"EXPLAIN (format json) SELECT * FROM state_info WHERE name='Alabama'\")\n",
    "state_query_plan = cur.fetchall()\n",
    "pp.pprint(state_query_plan)\n",
    "\n",
    "cur.execute(\"EXPLAIN (format json) SELECT * FROM state_household_incomes WHERE state='Georgia'\")\n",
    "incomes_query_plan = cur.fetchall()\n",
    "pp.pprint(incomes_query_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f74eb70",
   "metadata": {},
   "source": [
    ">Let's create a separate table that's optimized for lookups by a different column than `id` from the `homeless_by_coc` table. First, we assign the column we want to query part of the primary key, so we get the speed benefits, and add the next part of the primary key as the `id` value from the `homeless_by_coc`. We call this table an index and each row in the index contains:\n",
    ">\n",
    ">- the value we want to be able to search by,\n",
    ">- an `id` value for the corresponding row in `homeless_by_coc`,\n",
    ">- assign both as composite primary keys for the table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4619eea",
   "metadata": {},
   "source": [
    "- Use the provided `cur` object.\n",
    "- Create a table, `state_idx`, that contains the columns `state` and `homeless_id`.\n",
    "    - Create a composite primary key containing both `state` and `homeless_id`.\n",
    "    - Insert into `state_idx` the columns `state` and `id` from `homeless_by_coc`.\n",
    "- Select `state`, `year`, and `coc_number` from `homeless_by_coc` by joining with the `state_idx` id.\n",
    "    - Filter by `CA` state on `state_idx`.\n",
    "- Call `fetchall()` and pretty print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddd5cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT DISTINCT name from user\")\n",
    "names = pd.DataFrame(cur.fetchall())\n",
    "\n",
    "names.columns = ['name']\n",
    "names['stationid'] = [\"%03d\" % (x) for x in list(range(1,306))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca65058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"DROP TABLE stations;\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df31c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('postgresql+psycopg2://xtang:xtang@localhost/test_db')\n",
    "names.to_sql('stations', engine, dtype = {'name': sqlalchemy.types.CHAR(length=55), \\\n",
    "                                         'stationid':sqlalchemy.types.CHAR(length=3)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb62276a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT user.index, user.update, user.free, user.available, user.total, user.lat,\\\n",
    "            user.long, stations.stationid, stations.name\\\n",
    "             INTO user1\\\n",
    "             FROM user\\\n",
    "             FULL OUTER JOIN stations\\\n",
    "             ON stations.name = user.name\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e6f964",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT * from user2\")\n",
    "data = pd.DataFrame(cur.fetchall())\n",
    "\n",
    "data.columns = ['index', 'update', 'free', 'available', 'total', 'lat', 'long', 'stationid', 'name']\n",
    "station271 = data[data['stationid'] =='271']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03281d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT update, COUNT( stationid ) FROM user2 GROUP BY update HAVING COUNT (stationid)>1 ORDER BY update\")\n",
    "dupcheck = pd.DataFrame(cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c30301a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "DELETE FROM user2 \n",
    "WHERE index IN (SELECT index\n",
    "                 FROM (SELECT index, ROW_NUMBER() OVER (PARTITION BY stationid, update ORDER BY index) AS rnum \n",
    "                       FROM user2) t \n",
    "                 WHERE t.rnum >1);\n",
    "\"\"\"\n",
    "\n",
    "#read this query from the inside, out: What are the things we count as duplicates and lets groupby those things\n",
    "# Start with the groupby aka partition by:\n",
    "    # Station ID and Update\n",
    "    # Order by index - We created index a unique identifyer, it's just an ordered number by collection or 'update' time. \n",
    "# Now that we've grouped dups, select index and the new variable that we've created on the fly, called ROW_NUMBER\n",
    "    # ROWNUMBER counts the number of records stored for a particular stationid/update combination as we iterate through. \n",
    "    # Any stationid/update with a ROWNUMBER >1 will be a dup.\n",
    "    # We declare this as a table t and ROW NUMBER variable to be rnum\n",
    "    # Select all where Rownumber is >1, and delete it.\n",
    "    \n",
    "cur.execute(query) \n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158686ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"CREATE TABLE station_update_idx (update TIMESTAMP, stationid CHAR(3), PRIMARY KEY (update, stationid))\")\n",
    "cur.execute(\"INSERT INTO station_update_idx SELECT update, stationid FROM user2\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994a4bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT user2.available, user2.free FROM user2, station_update_idx idx\\\n",
    "             WHERE idx.update = '2018-02-20 07:12:19' AND idx.stationid = user2.stationid\")\n",
    "pp.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b377f07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"CREATE TABLE state_idx (state CHAR(2), homeless_id INT, PRIMARY KEY (state, homeless_id))\")\n",
    "cur.execute(\"INSERT INTO state_idx SELECT state, id FROM homeless_by_coc\")\n",
    "conn.commit()\n",
    "cur.execute(\"SELECT hbc.state, hbc.year, hbc.coc_number FROM homeless_by_coc hbc, state_idx WHERE state_idx.state = 'CA' AND state_idx.homeless_id=hbc.id\")\n",
    "pp.pprint(cur.fetchall()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2dd3b2",
   "metadata": {},
   "source": [
    "- Use the provided `cur` object.\n",
    "- Run the `EXPLAIN ANALYZE` on the query you built in the last screen.\n",
    "    - Format the ouptut with the json type.\n",
    "- Call `.fetchall()` and pretty print the output.\n",
    "- Run the `EXPLAIN ANALYZE` on a query that returns the columns `id`, `year`, and `coc_number`, and filters `state` equal to `CA` on the `homeless_by_coc` table.\n",
    "    - Format the ouptut with the `json` type.\n",
    "- Call `.fetchall()` and pretty print the output.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635e653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"\n",
    "            EXPLAIN (ANALYZE, format json) SELECT user2.available, user2.free FROM user2,\\\n",
    "                                                                                      station_update_idx idx\\\n",
    "            WHERE idx.update = '2018-02-20 07:12:19' AND idx.stationid = user2.stationid\n",
    "            \"\"\")\n",
    "pp.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e694ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"\n",
    "SELECT hbc.id, hbc.year, hbc.coc_number FROM homeless_by_coc hbc, state_idx\n",
    "WHERE state_idx.state = 'CA' AND state_idx.homeless_id = hbc.id\n",
    "\"\"\")\n",
    "pp.pprint(cur.fetchall())\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "EXPLAIN (ANALYZE, format json) SELECT hbc.id, hbc.year, hbc.coc_number FROM homeless_by_coc hbc, state_idx\n",
    "WHERE state_idx.state = 'CA' AND state_idx.homeless_id = hbc.id\n",
    "\"\"\")\n",
    "pp.pprint(cur.fetchall())\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "EXPLAIN (ANALYZE, format json) SELECT id, year, coc_number FROM homeless_by_coc WHERE state='CA'\n",
    "\"\"\")\n",
    "pp.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc4b173",
   "metadata": {},
   "source": [
    "- Use the provided `cur` and `conn` object.\n",
    "- Create an index on state for the `homeless_by_coc` table.\n",
    "    - Commit your changes.\n",
    "- Run `EXPLAIN ANALYZE` on a select all from `homeless_by_coc` and filter by `CA` on the indexed `state` column.\n",
    "    - Format the output with `json`.\n",
    "- Call `.fetchall()` and pretty print the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a229322",
   "metadata": {},
   "source": [
    ">By letting Postgres maintain the indexes, we know that they will remain up to date as rows are added to the table. In addition, Postgres will automatically take advantages of indexes whenever possible, so we can focus on writing queries. This occurs during the planning/optimization stage, which is why we can see it in the EXPLAIN query.\n",
    ">\n",
    ">While creating indexes gives us tremendous speed benefits, they come at the cost of space. Each index needs to be stored in the database file. In addition, adding, editing, and deleting rows takes longer since each of the affected indexes need to be updated. Because indexes can be created after a table is created, it's recommended to only create an index when you find yourself querying on a specific column frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89217e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"DROP INDEX state_idx\")\n",
    "conn.commit()\n",
    "cur.execute(\"CREATE INDEX state_idx ON homeless_by_coc(state)\")\n",
    "conn.commit()\n",
    "cur.execute(\"EXPLAIN (ANALYZE, format json) SELECT * FROM homeless_by_coc where state = 'CA'\")\n",
    "pp.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43b6028",
   "metadata": {},
   "source": [
    "- Use the provided `cur` and `conn` objects.\n",
    "- Proceeding the `EXPLAIN ANALYZE` command's `fetchall()`, drop the index on the `homeless_by_coc` table.\n",
    "    - Commit your changes.\n",
    "- Re-run `EXPLAIN ANALYZE` on a select all from `homeless_by_coc` and filter by `CA` on the indexed `state` column.\n",
    "    - Format the output with `json`.\n",
    "- Call `.fetchall()` and pretty print the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdafca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cur.execute(\"CREATE INDEX state_idx ON homeless_by_coc(state)\")\n",
    "#conn.commit()\n",
    "#cur.execute(\"EXPLAIN (ANALYZE, format json) SELECT * FROM homeless_by_coc WHERE state='CA'\")\n",
    "#pp.pprint(cur.fetchall())\n",
    "cur.execute(\"DROP INDEX IF EXISTS state_idx\")\n",
    "conn.commit()\n",
    "cur.execute(\"EXPLAIN (ANALYZE, format json) SELECT * FROM homeless_by_coc WHERE state = 'CA'\")\n",
    "pp.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffd4454",
   "metadata": {},
   "source": [
    "- Use the provided `cur` and `conn` objects.\n",
    "- Create and drop the index for `state` on `homeless_by_coc` to test the benchmark.\n",
    "    - Run `EXPLAIN ANALYZE` on the given join query for `homeless_by_coc` before and after the drop.\n",
    "    - Call `.fetchall()` to return the output.\n",
    "- Pretty print the output from `fechall()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1370a543",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cur.execute(\"CREATE INDEX state_idx ON homeless_by_coc(state)\")\n",
    "#conn.commit()\n",
    "query = \"EXPLAIN (ANALYZE, format json) SELECT hbc.state, hbc.coc_number, hbc.coc_name, si.name FROM homeless_by_coc as hbc, state_info as si WHERE hbc.state = si.postal\"\n",
    "\n",
    "cur.execute(query)\n",
    "pp.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51434d81",
   "metadata": {},
   "source": [
    "- Use the provided `cur` and `conn` object.\n",
    "- Create an index on `state` for the `homeless_by_coc` table.\n",
    "    - Commit your changes.\n",
    "- Run `EXPLAIN` on a select all from `homeless_by_coc`.\n",
    "    - Filter by `CA` on the indexed `state` column.\n",
    "    - Filter years greater than `1991-01-01` on the non-indexed `year` column.\n",
    "    - Format the output with `json`.\n",
    "- Call `.fetchall()` and pretty print the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350c4f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"DROP INDEX state_idx\")\n",
    "conn.commit()\n",
    "\n",
    "cur.execute(\"CREATE INDEX state_idx ON homeless_by_coc(state)\")\n",
    "conn.commit()\n",
    "\n",
    "cur.execute(\"EXPLAIN (format json) SELECT * FROM homeless_by_coc WHERE state = 'CA' AND year > '1991-01-01'\")\n",
    "pp.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced9de8b",
   "metadata": {},
   "source": [
    ">A `Bitmap Heap Scan` occurs when Postgres encounters two, or more, columns that contain an index. Our heap scan follows these steps:\n",
    ">\n",
    ">1. Run through the indexed column, state, and select all the rows that match CA. This is the `Bitmap Index Scan`.\n",
    ">2. Create a `Bitmap Heap` that is used as the temporary index.\n",
    ">3. Scan through the `Bitmap Heap`, and select all rows that have a year value greater than 1991-01-01. This is the `Bitmap Heap Scan`.\n",
    ">4. Return the results.\n",
    ">\n",
    ">This type of scan is more efficient than a pure Seq Scan, because the number of filtered rows in an index will always be less than or equal to the number of rows in the full table. Unfortunately, each filtered row must be sequentially searched again to find values that match the second filter (eg. year greater than 1991).\n",
    ">\n",
    ">We can eliminate the second sequential scan by adding an additional index on to another column in our table. This type of index is called a multi-column index. If you commonly run queries that filters two columns, then using a multi-column index can speed up your query times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f056e54",
   "metadata": {},
   "source": [
    "- Use the provided `cur` and `conn` objects.\n",
    "- Create and drop a single column index for `state` on `homeless_by_coc` to test the benchmark.\n",
    "    - Run `EXPLAIN ANALYZE` on a select all from `homeless_by_coc`.\n",
    "    - Filter by CA on the indexed `state` column.\n",
    "    - Filter years greater than `1991-01-01` on the non-indexed year column.\n",
    "    - Format the output with `json`.\n",
    "    - Call `fetchall()` and pretty print the output.\n",
    "- Create a multi-column index on state and year on `homeless_by_coc` and run the same `EXPLAIN ANALYZE`.\n",
    "    - pretty print the output from `fetchall()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fc3595",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"DROP INDEX IF EXISTS state_idx\")\n",
    "conn.commit()\n",
    "\n",
    "cur.execute(\"CREATE INDEX state_idx ON homeless_by_coc(state)\")\n",
    "conn.commit()\n",
    "\n",
    "cur.execute(\"EXPLAIN ANALYZE SELECT * FROM homeless_by_coc WHERE state = 'CA' AND year > '1991-01-01'\")\n",
    "pp.pprint(cur.fetchall())\n",
    "\n",
    "cur.execute(\"DROP INDEX IF EXISTS state_idx\")\n",
    "conn.commit()\n",
    "\n",
    "cur.execute(\"CREATE INDEX idx ON homeless_by_coc(state, year)\")\n",
    "cur.execute(\"EXPLAIN ANALYZE SELECT * FROM homeless_by_coc WHERE state = 'CA' AND year > '1991-01-01'\")\n",
    "pp.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d701603",
   "metadata": {},
   "source": [
    "- Use the provided `cur` and `conn` objects.\n",
    "- Create a multi-column index on `state`, `year`, and `coc_number` on `homeless_by_coc`.\n",
    "    - Use the convention of naming your index by `snake_casing` the columns in order.\n",
    "- Commit the index with the `conn` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199e6788",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"CREATE INDEX state_year_coc_number_idx ON homeless_by_coc(state, year, coc_number)\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ea2b34",
   "metadata": {},
   "source": [
    ">One or more indexes will impact the performance of your `INSERT` operations. As you increase the amount of indexes, the performance of `INSERT` decreases due to the additional index inserts. This can cause your table to fail when adding rows in a high load environment.\n",
    ">\n",
    ">Furthermore, because indexes are a separate structure, they also take up additional disk space in your database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ab6b33",
   "metadata": {},
   "source": [
    "- Use the provided `cur` and `conn` objects.\n",
    "- Run a copy statement that loads the `homeless_by_coc.csv` file into the `homeless_by_coc` table.\n",
    "    - Enclose the `COPY` by a start and end time, then print the `end_time`.\n",
    "- Delete all the rows in the `homeless_by_coc` table.\n",
    "- Create a double column index on `state`, `year` for `homeless_by_coc`.\n",
    "- Run another copy statement that loads the `homeless_by_coc.csv` file into the `homeless_by_coc` table.\n",
    "    - Enclose the `COPY` by a start and end time, then print the `end_time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddf7b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "filename = 'homeless_by_coc.csv'\n",
    "\n",
    "start_time = time.time()\n",
    "with open(filename) as f:\n",
    "    statement = cur.mogrify('COPY %s FROM STDIN WITH CSV HEADER', (AsIs(filename.split('.')[0]), ))\n",
    "    cur.copy_expert(statement, f)\n",
    "print(time.time() - start_time)\n",
    "\n",
    "cur.execute(\"DELETE FROM homeless_by_coc\")\n",
    "cur.execute(\"CREATE INDEX state_year_idx ON homeless_by_coc(state, year)\")\n",
    "\n",
    "start_time = time.time()\n",
    "with open(filename) as f:\n",
    "    statemnet = cur.mogrify('COPY %s FROM STDIN WITH CSV HEADER', (AsIs(filename.split(',')[0]), ))\n",
    "    cur.copy_expert(statement, f)\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43373da9",
   "metadata": {},
   "source": [
    "- Use the provided `cur` and `conn` objects.\n",
    "- Create a double column index on `state`, `year` for `homeless_by_coc`.\n",
    "    - Add the descending order by option to `year`.\n",
    "- Commit the index.\n",
    "- Run a select on `homeless_by_coc`.\n",
    "    - Select distinct `year`.\n",
    "    - Filter by CA on the indexed `state` column.\n",
    "    - Filter years greater than `1991-01-01` on the order by indexed year column.\n",
    "- Call `fetchall()` and assign the return value to `ordered_years`\n",
    "- pretty print `ordered_years`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f5d087",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"DROP INDEX IF EXISTS state_year_idx\")\n",
    "conn.commit()\n",
    "\n",
    "cur.execute(\"CREATE INDEX state_year_idx ON homeless_by_coc(state, year ASC)\")\n",
    "conn.commit()\n",
    "\n",
    "cur.execute(\"SELECT DISTINCT year FROM homeless_by_coc WHERE state = 'CA' AND year > '1991-01-01'\")\n",
    "ordered_years = cur.fetchall()\n",
    "pp.pprint(ordered_years)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1c40e4",
   "metadata": {},
   "source": [
    "- Use the provided `cur` and `conn` objects.\n",
    "- Create a case-insensitive expression index on measures for `homeless_by_coc`.\n",
    "- Commit the index.\n",
    "- Run a select all from `homeless_by_coc`.\n",
    "    - Filter `measures` to rows with `'unsheltered homeless people in families'`.\n",
    "    - Limit to 1 row.\n",
    "- Call `fetchone()` and assign the return value to `unsheltered_row`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe222b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"CREATE INDEX measures_idx ON homeless_by_coc(lower(measures))\")\n",
    "conn.commit()\n",
    "\n",
    "cur.execute(\"SELECT * FROM homeless_by_coc WHERE lower(measures)='unsheltered homeless people in families'\")\n",
    "unsheltered_row = cur.fetchone()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc57530",
   "metadata": {},
   "source": [
    "- Use the provided `cur` and `conn` objects.\n",
    "    - Create a partial index on `homeless_by_coc`.\n",
    "    - Index on the `state` column.\n",
    "- Restrict the index on all rows that have a count greater than 0.\n",
    "- Commit the index.\n",
    "- Run an `EXPLAIN ANALYZE` on a select all from `homeless_by_coc`.\n",
    "    - Filter `state` on CA and count greater than 0.\n",
    "    - Limit to 1 row.\n",
    "- Call `fetchall()` and pretty print the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e64557a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"CREATE INDEX idx ON homeless_by_coc(state) WHERE count > 0\")\n",
    "conn.commit()\n",
    "\n",
    "cur.execute(\"EXPLAIN ANALYZE SELECT * FROM homeless_by_coc WHERE state = 'CA' AND count > 0\")\n",
    "pp.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae963111",
   "metadata": {},
   "source": [
    "- Use the provided cur and conn objects.\n",
    "- Create a multi-column index that speeds up the following query:\n",
    "    - `SELECT hbc.year, si.name, hbc.count FROM homeless_by_coc hbc, state_info si WHERE hbc.state = si.postal AND hbc.year > '2007-01-01' AND hbc.measures != 'total homeless'`\n",
    "- Run `EXPLAIN ANALYZE` on the query.\n",
    "- Call `.fetchall()` and pretty print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35aee84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"CREATE INDEX state_year_measures_idx ON homeless_by_coc(state, lower(measures)) WHERE year > '2007-01-01'\")\n",
    "conn.commit()\n",
    "cur.execute(\"\"\"\n",
    "EXPLAIN ANALYZE SELECT hbc.year, si.name, hbc.count\n",
    "FROM homeless_by_coc hbc, state_info si WHERE hbc.state = si.postal\n",
    "AND hbc.year > '2007-01-01' AND hbc.measures != 'total homeless'\n",
    "\"\"\")\n",
    "pp.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecdc052",
   "metadata": {},
   "source": [
    "## Vaccuuming Postgres Databases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2069ccef",
   "metadata": {},
   "source": [
    ">Shouldn't the speed be the same? Why would query speeds be affected by a few deletes? In this mission, we will learn \n",
    "> the process by which Postgres runs destructive commands, the reason why it can have a non-trivial effect on querying \n",
    "> speeds, and the internal tools to reclaim the lost speed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd633d6",
   "metadata": {},
   "source": [
    "- Use the provided `cur` object.\n",
    "- Run the `DELETE FROM` command on `homeless_by_coc` to delete all the rows in the table.\n",
    "- Reload the data by running `INSERT` or running a `COPY FROM` psycopg2 cursor query that loads data from the  `homeless_by_coc.csv` file into the `homeless_by_coc` table.\n",
    "    - Commit your changes.\n",
    "- Using `execute()`, count the number of rows from `homeless_by_coc`.\n",
    "- Assign the `int` value return value to `homeless_rows`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d09eb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"DELETE FROM homeless_by_coc\")\n",
    "\n",
    "filename = 'homeless_by_coc.csv'\n",
    "with open(filename) as f:\n",
    "    cur.copy_expert('COPY homeless_by_coc FROM STDIN WITH CSV HEADER', f)\n",
    "conn.commit()\n",
    "\n",
    "cur.execute(\"SELECT COUNT(*) FROM homeless_by_coc\")\n",
    "homeless_rows = cur.fetchone()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f381b35a",
   "metadata": {},
   "source": [
    "`DELETE`<br>\n",
    "Instead of removing the rows from the table, Postgres will mark the rows as dead, which means they will be eventually removed, once the commit has succeeded.<br>\n",
    "- Dead rows helps keep consistency and isolation within a transaction<br>\n",
    "- Dead rows increase table size and will lengthen query times.\n",
    "- To check if a table has any hanging dead rows, we use an internal table from the `pg_catalog` called `pg_stat_all_tables` which contains a collection of helpful table statistics.<Br><Br>\n",
    "\n",
    "Transactions are a way to ensure multiple users can concurrently run commands.<br>\n",
    "\n",
    "All transactions follow a specific set of properties called ACID.\n",
    "\n",
    "- Atomicity: If one thing fails in the transaction, the whole transaction fails.\n",
    "- Consitency: A transaction will move the database from one valid state to another.\n",
    "- Isolation: Concurrent effects to the database will be followed through as sequential changes.\n",
    "- Durability: Once the transaction is commited, it will stay that way regardless of crash, power outage, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ee9be6",
   "metadata": {},
   "source": [
    "- Use the provided `cur` object.\n",
    "- Before the `DELETE` command, find the number of dead rows for the `homeless_by_coc` table.\n",
    "    - Print the result.\n",
    "- After loading the table, find the number of dead rows for the `homeless_by_coc` tables.\n",
    "- Assign the `int` return value to `homeless_dead_rows`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e038bd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT n_dead_tup FROM pg_stat_all_tables WHERE relname = 'homeless_by_coc'\")\n",
    "print(cur.fetchone()[0]) #prints 0\n",
    "\n",
    "cur.execute(\"DELETE FROM homeless_by_coc\")\n",
    "with open('homeless_by_coc.csv') as f:\n",
    "    cur.copy_expert('COPY homeless_by_coc FROM STDIN WITH CSV HEADER', f)\n",
    "conn.commit()\n",
    "\n",
    "cur.execute(\"SELECT COUNT(*) FROM homeless_by_coc\")\n",
    "homeless_dead_rows = cur.fetchone()[0] #prints 86529"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fc5878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pprint as pp\n",
    "\n",
    "conn = psycopg2.connect(dbname=\"test_db\", user=\"xtang\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"SELECT n_dead_tup FROM pg_stat_all_tables WHERE relname = 'users'\")\n",
    "print(cur.fetchone()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556413e3",
   "metadata": {},
   "source": [
    "- Use the provided `cur` object.\n",
    "- Note, we have already deleted the rows for you.\n",
    "- Try running a vacuum on `homeless_by_coc`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ae01d9",
   "metadata": {},
   "source": [
    "`VACUUM`\n",
    "- If you run `VACUUM` without a table name, it will vacuum every user created table the current logged in user has access to\n",
    "- Vacuuming a table will remove the marked dead rows\n",
    "- You have to do this in SQL because the command cannot run in a Transaction Block.\n",
    "- To run `VACUUM` outside a transaction block, we need to explicitly set the autocommit property of the psycopg2.Connection object. \n",
    "    - By setting autocommit to True, you are signalling to the `psycopg2` driver that you do not want your queries to run in a transaction block."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386f91b5",
   "metadata": {},
   "source": [
    "- Use the provided `cur` and `conn` objects.\n",
    "- Disable transaction blocks on the connection object.\n",
    "- Find the number of dead rows for the `homeless_by_coc` table.\n",
    "    - Print the result.\n",
    "- Run a vacuum on `homeless_by_coc`.\n",
    "- After vacuuming the table, find the number of dead rows for the `homeless_by_coc` tables.\n",
    "- Assign the int return value to `homeless_dead_rows`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35c472f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname=\"test_db\", user=\"xtang\", password=\"xtang\")\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT n_dead_tup FROM pg_stat_all_tables WHERE relname='homeless_by_coc'\")\n",
    "print(cur.fetchall()[0])\n",
    "cur.execute(\"VACUUM homeless_by_coc\")\n",
    "cur.execute(\"SELECT n_dead_tup FROM pg_stat_all_tables WHERE relname='homeless_by_coc'\")\n",
    "homeless_dead_rows = cur.fetchall()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1a5a84",
   "metadata": {},
   "source": [
    "- Use the provided `cur` and `conn` objects.\n",
    "    - Set the connection to execute outside transaction blocks.\n",
    "- Run an `EXPLAIN` query for a select all query on `homeless_by_coc`.\n",
    "    - Pretty print the results.\n",
    "- Vacuum analyze `homeless_by_coc`.\n",
    "- Rerun the explain query.\n",
    "- Pretty print the results from the explain query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a6b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname=\"test_db\", user=\"xtang\", password=\"xtang\")\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"EXPLAIN SELECT * FROM homeless_by_coc\")\n",
    "pp.pprint(cur.fetchall())\n",
    "\n",
    "cur.execute(\"VACUUM ANALYZE homeless_by_coc\")\n",
    "cur.execute(\"EXPLAIN SELECT * FROM homeless_by_coc\")\n",
    "pp.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d362b90",
   "metadata": {},
   "source": [
    "- Use the provided `cur` and `conn` objects.\n",
    "- Set the connection to execute outside a transaction block.\n",
    "- Using `cur.execute()`, vacuum full all user created tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf2bae8",
   "metadata": {},
   "source": [
    "The most powerful and risky `VACUUM` option: `FULL`\n",
    "- Reclaims space for the entire database server\n",
    "- Claims an <b>exclusive</b> lock on the table it is vacuuming\n",
    "    - This means that no insert, update, or delete queries can be issued against that table during the vacuum duration. \n",
    "    - Select queries on the table are considerably slowed down to the point where they are unusable.\n",
    "- When we described a general `VACUUM`, we stated that it will remove dead rows from the table and reclaim their lost space. However, that disk space is never freed, it is still assigned to the table as extra space to be used when more data is inserted.\n",
    "- `VACUUM FULL` will free the disk space for the whole server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7c0ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname=\"test_db\", user=\"xtang\", password=\"xtang\")\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"VACUUM FULL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7af5711",
   "metadata": {},
   "source": [
    "> Postgres has a feature called <b>autovacuum</b> and it runs periodically on your tables to ensure that dead rows are removed, and your statistics are up to date.\n",
    ">\n",
    "> In the latest versions of Postgres, autovacuum is on by default, and requires no additional setup.\n",
    ">\n",
    "> When do we explicitly vacuum tables?\n",
    "> 1. Are you running your normal analysis tasks without major table deletes and load? Then, leave vacuuming to the autovacuum.\n",
    ">\n",
    ">2. Have you recently deleted a significant amount of data in your tables, and you want to follow it up with complex analysis commands? Then, run a `VACUUM` or `VACUUM ANALYZE` to ensure optimized query commands.\n",
    ">\n",
    ">3. Are your tables growing out of control, and is there little free space left on the database server? Then, disable all queries and run a `VACUUM FULL` to reclaim a signficant amount of space."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
